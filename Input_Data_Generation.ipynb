{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the Noise Files\n",
    "\n",
    "import librosa\n",
    "noise1,sr1=sf.read(r\"Noise Data/adtBabble2.wav\")\n",
    "noise2,sr2=sf.read(r\"Noise Data/adtCafe.wav\")\n",
    "noise3,sr3=sf.read(r\"Noise Data/Live_Restaurant.wav\")\n",
    "\n",
    "adtBabble2 = librosa.resample(noise1,sr1,16000)\n",
    "adtCafe = librosa.resample(noise2,sr2,16000)\n",
    "Live_Restaurant = librosa.resample(noise3[:,0],sr3,16000)\n",
    "\n",
    "# Divide each noise files into Training and Testing Set (50% each)\n",
    "mid=len(adtBabble2)//2\n",
    "train_adtBabble2 = adtBabble2[:mid]\n",
    "test_adtBabble2 = adtBabble2[mid:]\n",
    "\n",
    "mid=len(adtCafe)//2\n",
    "train_adtCafe = adtCafe[:mid]\n",
    "test_adtCafe = adtCafe[mid:]\n",
    "\n",
    "\n",
    "mid=len(Live_Restaurant)//2\n",
    "\n",
    "train_Live_Restaurant = Live_Restaurant[:mid]\n",
    "test_Live_Restaurant = Live_Restaurant[mid:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each clean speech signal from the training (and development) data set, randomly select an equal length, contiguous segment from the noise training (and development) signal. For each speech and noise signal pair, generate noisy speech at signal-to-noise ratios (SNRs) of: -3, 0, and 3 dB. Meaning, for 1000 training signals (500 from male and 500 from female), 1 noise segment, 3 noise signals, and 3 SNRs per signal pair, there should be 1000 x 1 x 3 x 3 = 9000 training signals. Be sure to keep track of the corresponding clean speech signal for each noisy speech signal. You may want to rename the files and output as wav files to a different directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: Train Length: 500 , Dev Length 100 , Test length 100 \n",
      "Female: Train Length: 500 , Dev Length 100 , Test length 100 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_male_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_male/train_male\")\n",
    "dev_male_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_male/development_male\")\n",
    "test_male_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_male/test_male\")\n",
    "\n",
    "train_female_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_female/train_female\")\n",
    "dev_female_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_female/development_female\")\n",
    "test_female_filenames=os.listdir(r\"Speech Data/IEEE/IEEE_female/test_female\")\n",
    "\n",
    "print(\"Male: Train Length: {} , Dev Length {} , Test length {} \".format(len(train_male_filenames),len(dev_male_filenames),len(test_male_filenames)))\n",
    "print(\"Female: Train Length: {} , Dev Length {} , Test length {} \".format(len(train_female_filenames),len(dev_female_filenames),len(test_female_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_calculate(speech_data,noise_data):\n",
    "    speech_energy=np.sum(np.array(speech_data, dtype='int64')**2)\n",
    "    noise_energy=np.sum(np.array(noise_data, dtype='int64')**2)\n",
    "    ratio=speech_energy/noise_energy\n",
    "    sound_level=10*math.log(ratio,10)\n",
    "    return sound_level\n",
    "# Function that creates noisy speech signal by combining noise and clean speech at desired SNR level.\n",
    "def generate_signal(speech_data,noise_data,dsnr,outputfilename):\n",
    "    speech_energy=sum(np.array(speech_data)**2)\n",
    "    noise_energy=np.sum(np.array(noise_data)**2)\n",
    "    b=np.sqrt((speech_energy/noise_energy)*(10**(-dsnr/10)))\n",
    "    updated_noise=b*noise_data\n",
    "#     print(\"Noise : \",len(updated_noise))\n",
    "#     print(\"Speech : \",len(speech_data))\n",
    "    updated_noisy_signal=updated_noise+speech_data\n",
    "#     print(\"Speech : \",len(updated_noisy_signal))\n",
    "    sf.write(file=outputfilename,data=updated_noisy_signal,samplerate=16000)\n",
    "    ss,sr = librosa.load(outputfilename,sr=None)\n",
    "    S = librosa.stft(ss,n_fft=512,hop_length=160,win_length=320)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training \n",
    "for filename in train_male_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/TRAIN_MALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_male/train_male/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([train_adtBabble2,train_adtCafe,train_Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development\n",
    "for filename in dev_male_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/DEV_MALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_male/development_male/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([adtBabble2,adtCafe,Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n",
    "\n",
    "# For Testing\n",
    "for filename in test_male_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/TEST_MALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_male/test_male/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([adtBabble2,adtCafe,Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training \n",
    "\n",
    "for filename in train_female_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/TRAIN_FEMALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_female/train_female/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([adtBabble2,adtCafe,Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development\n",
    "for filename in dev_female_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/DEV_FEMALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_female/development_female/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([adtBabble2,adtCafe,Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n",
    "\n",
    "# For Testing\n",
    "for filename in test_female_filenames:\n",
    "    destination_file_name=\"PREPARED_DATASET/TEST_FEMALE/\"+str(filename).split('.')[0]\n",
    "    complete_filename=\"Speech Data/IEEE/IEEE_female/test_female/\"+str(filename)\n",
    "    speech_signal,sr=sf.read(complete_filename)\n",
    "    speech_signal = librosa.resample(speech_signal,sr,16000)\n",
    "    len_speech_signal=len(speech_signal)\n",
    "    for index1,each_noisy_signal in enumerate([adtBabble2,adtCafe,Live_Restaurant]):\n",
    "        start=np.random.randint(0,len(each_noisy_signal)-len_speech_signal)\n",
    "        for index2,each_snr in enumerate([-3,0,3]):\n",
    "            generate_signal(speech_signal,each_noisy_signal[start:start+len_speech_signal],each_snr,destination_file_name+'__'+str(index1)+\"_\"+str(index2)+'.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ --> 10 Files\n",
      "    .ipynb_checkpoints/ --> 2 Files\n",
      "    Noise Data/ --> 3 Files\n",
      "    PREPARED_DATASET/ --> 0 Files\n",
      "        .ipynb_checkpoints/ --> 0 Files\n",
      "        DEV_FEMALE/ --> 900 Files\n",
      "        DEV_MALE/ --> 900 Files\n",
      "        TEST_FEMALE/ --> 900 Files\n",
      "        TEST_MALE/ --> 900 Files\n",
      "        TRAIN_FEMALE/ --> 4500 Files\n",
      "        TRAIN_MALE/ --> 4500 Files\n",
      "    Speech Data/ --> 0 Files\n",
      "        IEEE/ --> 0 Files\n",
      "            IEEE_female/ --> 20 Files\n",
      "                development_female/ --> 100 Files\n",
      "                test_female/ --> 100 Files\n",
      "                train_female/ --> 500 Files\n",
      "            IEEE_male/ --> 20 Files\n",
      "                development_male/ --> 100 Files\n",
      "                test_male/ --> 100 Files\n",
      "                train_male/ --> 500 Files\n"
     ]
    }
   ],
   "source": [
    "# Below function is a simple helper function sourced from https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python.\n",
    "# It is just for the sake of easy walkthrough of my directory and no of files in a particular directory.\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        subindent = ' ' * 0 * (level + 1)\n",
    "        print('{}{}/ --> {}{} Files'.format(indent, os.path.basename(root),subindent, len(files)))\n",
    "list_files('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
